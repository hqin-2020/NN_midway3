2022-09-25 18:56:40.239967: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2022-09-25 18:56:40.245429: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/cudnn-8.3.1-el8-x86_64/lib64
2022-09-25 18:56:40.245457: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2022-09-25 18:56:45.259022: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/cudnn-8.3.1-el8-x86_64/lib64
2022-09-25 18:56:45.259067: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-09-25 18:56:45.259088: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (midway3-0126.rcc.local): /proc/driver/nvidia/version does not exist
2022-09-25 18:56:45.259472: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-25 18:57:22.024639: W tensorflow/core/common_runtime/forward_type_inference.cc:231] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:
type_id: TFT_OPTIONAL
args {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_TENSOR
    args {
      type_id: TFT_BOOL
    }
  }
}
 is neither a subtype nor a supertype of the combined inputs preceding it:
type_id: TFT_OPTIONAL
args {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_TENSOR
    args {
      type_id: TFT_DOUBLE
    }
  }
}

	while inferring type of node 'StatefulPartitionedCall_1/StatefulPartitionedCall/cond_1_259/output/_29750'
Iter: 1 loss: 0.038021368585968114
Iter: 2 loss: 0.099385111995790532
Iter: 3 loss: 0.033922019416382648
Iter: 4 loss: 0.026861062045271361
Iter: 5 loss: 0.0072140919053765643
Iter: 6 loss: 0.0688584193504672
Iter: 7 loss: 0.0022312834554913067
Iter: 8 loss: 0.001918226918432867
Iter: 9 loss: 0.0018155009707237707
Iter: 10 loss: 0.001696080089669014
Iter: 11 loss: 0.00092256619172100126
Iter: 12 loss: 0.000792702041610331
Iter: 13 loss: 0.00078492836163439588
Iter: 14 loss: 0.00078420152585069957
Iter: 15 loss: 0.00078178666638747181
Iter: 16 loss: 0.00076209846368625422
Iter: 17 loss: 0.00069478843983846253
Iter: 18 loss: 0.0006452600478342996
Iter: 19 loss: 0.00063998526929149072
Iter: 20 loss: 0.00063769974597343768
Iter: 21 loss: 0.00063480244548872193
Iter: 22 loss: 0.00063036001616155371
Iter: 23 loss: 0.00062091770347198609
Iter: 24 loss: 0.00060828494347331787
Iter: 25 loss: 0.00059206632319219732
Iter: 26 loss: 0.00057700465005541552
Iter: 27 loss: 0.00055777730591816967
Iter: 28 loss: 0.00055504786942815981
Iter: 29 loss: 0.00054898117507269661
Iter: 30 loss: 0.00054190431664663443
Iter: 31 loss: 0.00053406970083748253
Iter: 32 loss: 0.00052812920335745805
Iter: 33 loss: 0.000520348384311045
Iter: 34 loss: 0.00050736889221279443
Iter: 35 loss: 0.00048266908433852246
Iter: 36 loss: 0.00056279967515294386
Iter: 37 loss: 0.00045580645222822937
Iter: 38 loss: 0.0004656059339551655
Iter: 39 loss: 0.00043459355507387135
Iter: 40 loss: 0.00040878291037979662
Iter: 41 loss: 0.00039313327279945164
Iter: 42 loss: 0.00037435600834544039
Iter: 43 loss: 0.0003634667223667445
Iter: 44 loss: 0.0011656468605983328
Iter: 45 loss: 0.0003548522927961349
Iter: 46 loss: 0.0003527827289888104
Iter: 47 loss: 0.00034815684090197394
Iter: 48 loss: 0.000344987641455717
Iter: 49 loss: 0.00034099900122241706
Iter: 50 loss: 0.00033476677838029751
Iter: 51 loss: 0.000328159825001858
Iter: 52 loss: 0.00030095756183625468
Iter: 53 loss: 0.00039138326929630566
Iter: 54 loss: 0.00029444976668117776
Iter: 55 loss: 0.00026899623865070962
Iter: 56 loss: 0.00023291623607652717
Iter: 57 loss: 0.00021378370174296105
Iter: 58 loss: 0.00020679244019581754
Iter: 59 loss: 0.00019639341993530859
Iter: 60 loss: 0.000180699566361928
Iter: 61 loss: 0.00013865036858972741
Iter: 62 loss: 9.8801662815684992e-05
Iter: 63 loss: 7.8423062787113471e-05
Iter: 64 loss: 7.3743533037828234e-05
Iter: 65 loss: 6.1823562293788456e-05
Iter: 66 loss: 5.7892673308664215e-05
Iter: 67 loss: 5.4554601464363022e-05
Iter: 68 loss: 4.1106638309548639e-05
Iter: 69 loss: 3.5064024683677115e-05
Iter: 70 loss: 3.0207705856401385e-05
Iter: 71 loss: 2.8087961021456106e-05
Iter: 72 loss: 2.7787252261475391e-05
Iter: 73 loss: 2.7745952200283011e-05
Iter: 74 loss: 2.7703303989725254e-05
Iter: 75 loss: 2.7612113563056758e-05
Iter: 76 loss: 2.7513926081143831e-05
Iter: 77 loss: 2.719996251930089e-05
Iter: 78 loss: 2.6369483007278414e-05
Iter: 79 loss: 2.4808064585461725e-05
Iter: 80 loss: 2.3127209298223518e-05
Iter: 81 loss: 1.9796881723210098e-05
Iter: 82 loss: 1.7841899759921856e-05
Iter: 83 loss: 1.776782817159559e-05
Iter: 84 loss: 1.756930175914178e-05
Iter: 85 loss: 1.7189362421919672e-05
Iter: 86 loss: 1.7185555269814797e-05
Iter: 87 loss: 1.7076969706492412e-05
Iter: 88 loss: 1.6943596868995584e-05
Iter: 89 loss: 1.6888171596933906e-05
Iter: 90 loss: 1.6807354922551391e-05
Iter: 91 loss: 1.6624740169909591e-05
Iter: 92 loss: 1.6048840245892385e-05
Iter: 93 loss: 1.4894795033314024e-05
Iter: 94 loss: 1.3867294748817463e-05
Iter: 95 loss: 1.2200808141408012e-05
Iter: 96 loss: 1.091059348110183e-05
Iter: 97 loss: 1.0986501130445002e-05
Iter: 98 loss: 8.1913858854169871e-06
Iter: 99 loss: 7.2749781152149339e-06
Iter: 100 loss: 5.7634901171437936e-06
Iter: 101 loss: 5.1647408192623056e-06
Iter: 102 loss: 4.65649054055304e-06
Iter: 103 loss: 4.4227030294683566e-06
Iter: 104 loss: 4.2116020238134522e-06
Iter: 105 loss: 4.1108936445946113e-06
Iter: 106 loss: 4.034089938787859e-06
Iter: 107 loss: 3.8904476845231163e-06
Iter: 108 loss: 3.7285631393533131e-06
Iter: 109 loss: 3.6446606538342228e-06
Iter: 110 loss: 3.6354340899335758e-06
Iter: 111 loss: 3.6302432438596265e-06
Iter: 112 loss: 3.6157227952376077e-06
Iter: 113 loss: 3.6006153534054348e-06
Iter: 114 loss: 3.57817718391374e-06
Iter: 115 loss: 3.5594503578544993e-06
Iter: 116 loss: 3.54038463607417e-06
Iter: 117 loss: 3.5194162401219373e-06
Iter: 118 loss: 3.4843356470681676e-06
Iter: 119 loss: 3.4518302745944757e-06
Iter: 120 loss: 3.4381896929369284e-06
Iter: 121 loss: 3.4354337276411246e-06
Iter: 122 loss: 3.4322294765961906e-06
Iter: 123 loss: 3.4146225210477533e-06
Iter: 124 loss: 3.3841777169105034e-06
Iter: 125 loss: 3.3095012365039178e-06
Iter: 126 loss: 3.1624482623900019e-06
Iter: 127 loss: 2.9325892734223078e-06
Iter: 128 loss: 2.6205574808796393e-06
Iter: 129 loss: 2.572783622657053e-06
Iter: 130 loss: 2.4695540247310192e-06
Iter: 131 loss: 2.1913581618039351e-06
Iter: 132 loss: 2.0898451605995344e-06
Iter: 133 loss: 1.9358219520631046e-06
Iter: 134 loss: 1.8235264579761302e-06
Iter: 135 loss: 1.7758771155203386e-06
Iter: 136 loss: 1.7233827585264685e-06
Iter: 137 loss: 1.6867676741442259e-06
Iter: 138 loss: 1.6609727797672762e-06
Iter: 139 loss: 1.6340633562488577e-06
Iter: 140 loss: 1.6235531044784319e-06
Iter: 141 loss: 1.6174119606162261e-06
Iter: 142 loss: 1.6108960133247248e-06
Iter: 143 loss: 1.6059367327867932e-06
Iter: 144 loss: 1.5978322668513123e-06
Iter: 145 loss: 1.5766119595590601e-06
Iter: 146 loss: 1.5409245959617808e-06
Iter: 147 loss: 1.4677525647730226e-06
Iter: 148 loss: 1.3962298175322041e-06
Iter: 149 loss: 1.5940453804984374e-06
Iter: 150 loss: 1.3461536346580418e-06
Iter: 151 loss: 1.6230270602369167e-06
Iter: 152 loss: 1.2895591451160975e-06
Iter: 153 loss: 1.2569353946780321e-06
Iter: 154 loss: 1.2330432314715937e-06
Iter: 155 loss: 1.1981418889230265e-06
Iter: 156 loss: 1.1596434776257027e-06
Iter: 157 loss: 1.1444892185838169e-06
Iter: 158 loss: 1.1297284147013055e-06
Iter: 159 loss: 1.1232827265280813e-06
Iter: 160 loss: 1.1172751205884548e-06
Iter: 161 loss: 1.1085034851400149e-06
Iter: 162 loss: 1.1066575704435564e-06
Iter: 163 loss: 1.105653536707553e-06
Iter: 164 loss: 1.1052009119742067e-06
Iter: 165 loss: 1.1047466472975916e-06
Iter: 166 loss: 1.1036882530470603e-06
Iter: 167 loss: 1.0970342751263279e-06
Iter: 168 loss: 1.0852286310201524e-06
Iter: 169 loss: 1.0536432584627764e-06
Iter: 170 loss: 9.9412183890648466e-07
Iter: 171 loss: 9.3241960296097065e-07
Iter: 172 loss: 9.5152025787669712e-07
Iter: 173 loss: 8.9662367634882885e-07
Iter: 174 loss: 8.66570625385565e-07
Iter: 175 loss: 8.5640443809361882e-07
Iter: 176 loss: 8.5167715775850114e-07
Iter: 177 loss: 8.5119209597116988e-07
Iter: 178 loss: 8.5087714235432846e-07
Iter: 179 loss: 8.4945608827783e-07
Iter: 180 loss: 8.45945523749523e-07
Iter: 181 loss: 8.4220977298412188e-07
Iter: 182 loss: 8.3584761250602323e-07
Iter: 183 loss: 8.2803445523833887e-07
Iter: 184 loss: 8.2055756487100847e-07
Iter: 185 loss: 8.1413782660642409e-07
Iter: 186 loss: 8.0864101022780525e-07
Iter: 187 loss: 7.9405532776326477e-07
Iter: 188 loss: 7.6941589859336528e-07
Iter: 189 loss: 7.4186810713721783e-07
Iter: 190 loss: 7.1899509797119169e-07
Iter: 191 loss: 6.860921543396401e-07
Iter: 192 loss: 6.6386441827242348e-07
Iter: 193 loss: 6.5316167487824732e-07
slurmstepd: error: *** JOB 4560762 ON midway3-0126 CANCELLED AT 2022-09-25T18:58:02 ***
