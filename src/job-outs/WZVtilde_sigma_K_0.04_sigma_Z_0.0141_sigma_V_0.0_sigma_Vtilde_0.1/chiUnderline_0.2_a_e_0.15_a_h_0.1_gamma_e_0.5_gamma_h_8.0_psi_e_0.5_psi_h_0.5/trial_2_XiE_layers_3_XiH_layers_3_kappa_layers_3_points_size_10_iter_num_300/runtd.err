2022-10-02 22:59:39.973630: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-10-02 22:59:40.133926: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2022-10-02 22:59:40.139845: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/python-anaconda-2022.05-el8-x86_64/lib:/software/cudnn-8.3.1-el8-x86_64/lib64
2022-10-02 22:59:40.139868: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2022-10-02 22:59:40.167212: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-10-02 22:59:40.885914: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/python-anaconda-2022.05-el8-x86_64/lib:/software/cudnn-8.3.1-el8-x86_64/lib64
2022-10-02 22:59:40.886012: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/python-anaconda-2022.05-el8-x86_64/lib:/software/cudnn-8.3.1-el8-x86_64/lib64
2022-10-02 22:59:40.886024: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2022-10-02 22:59:43.677278: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/python-anaconda-2022.05-el8-x86_64/lib:/software/cudnn-8.3.1-el8-x86_64/lib64
2022-10-02 22:59:43.677315: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)
2022-10-02 22:59:43.677334: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (midway3-0063.rcc.local): /proc/driver/nvidia/version does not exist
2022-10-02 22:59:43.677690: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-10-02 23:00:21.507263: W tensorflow/core/common_runtime/forward_type_inference.cc:332] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:
type_id: TFT_OPTIONAL
args {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_TENSOR
    args {
      type_id: TFT_BOOL
    }
  }
}
 is neither a subtype nor a supertype of the combined inputs preceding it:
type_id: TFT_OPTIONAL
args {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_TENSOR
    args {
      type_id: TFT_DOUBLE
    }
  }
}

	while inferring type of node 'StatefulPartitionedCall_1/StatefulPartitionedCall/cond_1_259/output/_29750'
Iter: 1 loss: 0.11683473524339978
Iter: 2 loss: 1.8229792176996358e-05
Iter: 3 loss: 1.821762139921782e-05
Iter: 4 loss: 1.8169089325142818e-05
Iter: 5 loss: 1.7977357651912593e-05
Iter: 6 loss: 1.7247459051182828e-05
9442803.0634124782
Iter: 1 loss: 2160577489.1136603
37265593969.0397
Iter: 2 loss: 67808255139906576
9417956.9938973337
Iter: 3 loss: 2157817400.9562888
9079596.5165534485
Iter: 4 loss: 2127725441.2445724
8933190.7154319435
Iter: 5 loss: 2114222386.6157022
8673831.5262595546
Iter: 6 loss: 2080389835.420248
8299666.8458983954
Iter: 7 loss: 1993949103.0877051
7498886.7949768323
Iter: 8 loss: 1642689427.1797667
6245820.4140083529
Iter: 9 loss: 1000263302.6650273
5573670.4610917158
Iter: 10 loss: 698930426.26305127
5193942.44130869
Iter: 11 loss: 544616583.35060573
5074097.099565614
Iter: 12 loss: 497796569.27848375
5043779.15879548
Iter: 13 loss: 488254243.195817
5004973.3838142958
Iter: 14 loss: 479476618.93945849
4856348.782267685
Iter: 15 loss: 449878394.77786934
4514342.8749508867
Iter: 16 loss: 385690419.03810227
3900465.8727682326
Iter: 17 loss: 270975131.72440374
3304012.1309578633
Iter: 18 loss: 168636696.16891876
2763580.5648706332
Iter: 19 loss: 107678443.62854254
2594278.0988525674
Iter: 20 loss: 73305417.930403084
2269260.4355851463
Iter: 21 loss: 54459976.604939677
2228625.5037914044
Iter: 22 loss: 49966848.12194331
2227523.1880463571
Iter: 23 loss: 49309413.931792364
2227302.0983379451
Iter: 24 loss: 48822436.487541363
2244089.6025844417
Iter: 25 loss: 47656275.086997
2258659.6382868919
Iter: 26 loss: 46943549.272723734
2200370.0522821024
Iter: 27 loss: 45827692.666485377
2186547.6632244065
Iter: 28 loss: 45699921.104820669
2165122.159170486
Iter: 29 loss: 45540422.516157769
2155429.970709186
Iter: 30 loss: 45494988.312743664
2143680.92656289
Iter: 31 loss: 45436957.345804572
2127781.90132342
Iter: 32 loss: 45329549.325420029
2106234.5144165354
Iter: 33 loss: 45073821.455604807
-684214.34618984978
Iter: 1 loss: 7124759.1968649076
2383257060.2592974
Iter: 2 loss: 144509886093.58932
82580.8512918884
Iter: 3 loss: 16370.319519579052
83649.2385206443
Iter: 4 loss: 15310.933266267553
90554.092061845091
Iter: 5 loss: 9850.4732063200317
94183.966221121838
Iter: 6 loss: 7810.9416474759373
97318.930691265472
Iter: 7 loss: 6432.9710511922913
99575.2224953107
Iter: 8 loss: 5566.5235551464984
101939.64991019892
Iter: 9 loss: 4998.79814793811
103228.85644614669
Iter: 10 loss: 4623.01014205112
103878.92506405633
Iter: 11 loss: 4514.8795516050013
104718.50493869277
Iter: 12 loss: 4315.8957224286532
107746.43288698111
Iter: 13 loss: 3522.8762533601575
110083.35178950027
Iter: 14 loss: 2853.607521594734
111350.92379753996
Iter: 15 loss: 2493.95747976516
111888.94735040553
Iter: 16 loss: 2377.8453454067349
112119.58676557224
Iter: 17 loss: 2317.7748141734628
112444.38595274021
Iter: 18 loss: 2208.17866477535
112496.4683797982
Iter: 19 loss: 2144.2155774645871
112594.49755898985
Iter: 20 loss: 2099.7214885401381
112645.70589694445
Iter: 21 loss: 2067.0016472231391
112625.3871177423
Iter: 22 loss: 2059.651095915337
112586.10394869835
Iter: 23 loss: 2058.5246606420264
112584.95350513101
Iter: 24 loss: 2057.9035254237419
112589.31146931756
Iter: 25 loss: 2056.2711704199251
112608.23637498266
Iter: 26 loss: 2053.0373878593737
112677.34046214413
Iter: 27 loss: 2044.0130457443163
112848.62974337859
Iter: 28 loss: 2024.9531247779269
113182.84743062819
Iter: 29 loss: 1992.2867656322505
113632.06043485511
Iter: 30 loss: 1951.3769867729309
114171.04045410696
Iter: 31 loss: 1902.1239159644206
114545.02291491028
Iter: 32 loss: 1876.3827183868277
Iter: 1 loss: 1.7560458949167205e-05
Iter: 2 loss: 9.5035696867983085e-06
127046.73554632434
Iter: 1 loss: 58012.777085868132
7943469.0947190905
Iter: 2 loss: 2981654895.9374528
317943.88878394256
Iter: 3 loss: 2102549.2175696734
132498.35501985837
Iter: 4 loss: 46028.216435124319
88242.951335935111
Iter: 5 loss: 2718.8454033259977
112115.7935574525
Iter: 6 loss: 20959.56834235269
101997.52600515915
Iter: 7 loss: 8903.24880430915
405119.44509650557
Iter: 8 loss: 3285335.349252807
104095.21613263218
Iter: 9 loss: 9889.679063564301
101620.48829231386
Iter: 10 loss: 8271.0256713766757
101608.75797722727
Iter: 11 loss: 8270.0956233327852
101604.25843707845
Iter: 12 loss: 8269.7548196762182
101595.05241827745
Iter: 13 loss: 8268.7494322947077
101578.39492287976
Iter: 14 loss: 8266.2282264364039
101544.62086944051
Iter: 15 loss: 8259.53138209922
101474.11930382444
Iter: 16 loss: 8242.2105683319623
101319.48033507846
Iter: 17 loss: 8197.4799910199927
100978.29602184241
Iter: 18 loss: 8085.2722421775443
100272.11594287255
Iter: 19 loss: 7822.9279063098293
99167.044469066925
Iter: 20 loss: 7344.0226535347847
98495.517472499589
Iter: 21 loss: 6977.7027361721457
98432.4508323962
Iter: 22 loss: 6903.28003580641
98455.951402089544
Iter: 23 loss: 6863.783881897325
98476.241952644414
Iter: 24 loss: 6862.3028527474507
98477.204625729151
Iter: 25 loss: 6862.0814401108855
98481.2660815939
Iter: 26 loss: 6861.3033919778054
98491.102499330824
Iter: 27 loss: 6855.4647954618122
98492.914681537863
Iter: 28 loss: 6840.5465588612833
98460.8181862618
Iter: 29 loss: 6803.1529288619595
98324.62922591588
Iter: 30 loss: 6715.437812732931
97905.923167813977
Iter: 31 loss: 6526.5848772983827
96725.1502609123
Iter: 32 loss: 6120.1156706150823
93693.514161769708
Iter: 33 loss: 5297.3596203199068
90971.959455494929
Iter: 34 loss: 4967.1879839670491
90882.275031321944
Iter: 35 loss: 4910.14294574717
90154.150310632569
Iter: 36 loss: 4854.753592166544
89535.897180643151
Iter: 37 loss: 4829.4159916120243
88917.913439946569
Iter: 38 loss: 4810.7240813476546
118040.72298458341
Iter: 1 loss: 3760.1477242774913
268499.95539713587
Iter: 2 loss: 8123.652289703763
14693.5518142033
Iter: 3 loss: 0.58291980693830359
14693.508573208986
Iter: 4 loss: 0.582910545636658
14693.335763695683
Iter: 5 loss: 0.5828735181708089
14692.646999593668
Iter: 6 loss: 0.582725693978189
14689.93006513533
Iter: 7 loss: 0.58213899918611278
14679.452450129396
Iter: 8 loss: 0.57985931587149531
14646.942410668737
Iter: 9 loss: 0.57242658792343315
14388.363695295528
Iter: 10 loss: 0.55579080248954182
13953.545328778224
Iter: 11 loss: 0.52423449744676831
12343.843319240386
Iter: 12 loss: 0.4195099767445975
8952.292531040719
Iter: 13 loss: 0.25950968354564707
6121.6442118957921
Iter: 14 loss: 0.32555724129282587
7254.6981007443737
Iter: 15 loss: 0.21405585683486902
6423.30479592133
Iter: 16 loss: 0.19076151612010067
5561.58889536627
Iter: 17 loss: 0.16763408550423936
5086.7732563808395
Iter: 18 loss: 0.86055069372129989
5224.91106395383
Iter: 19 loss: 0.15851633328017489
5166.3871011893443
Iter: 20 loss: 0.15646740300065162
5073.7402919543556
Iter: 21 loss: 0.15700237834905245
5117.5755042119454
Iter: 22 loss: 0.15572083032002887
5092.2479798733721
Iter: 23 loss: 0.15559381523195831
5090.28396613706
Iter: 24 loss: 0.15548626850700628
5005.477567962047
Iter: 25 loss: 0.15335468259330542
4803.6655052266715
Iter: 26 loss: 0.15103281340685176
4463.0922517938079
Iter: 27 loss: 0.14829170652958329
4068.5115611618676
Iter: 28 loss: 0.14660990590883155
3820.109531564779
Iter: 29 loss: 0.14661611692315094
4000.3982010993232
Iter: 30 loss: 0.14631547075257179
3825.3632133278807
Iter: 31 loss: 0.14940190728946731
3952.9042172640275
Iter: 32 loss: 0.14578365291434889
3947.5099388942281
Iter: 33 loss: 0.15199264782882849
3947.5299793047193
Iter: 34 loss: 0.14550673989196911
3992.0813628065089
Iter: 35 loss: 0.15054200014043481
3950.2478317500854
Iter: 36 loss: 0.14552639421822811
3948.0535662804332
Iter: 37 loss: 0.14550040619178289
3949.44554503388
Iter: 38 loss: 0.14550811146212114
3948.3351485547164
Iter: 39 loss: 0.14549957627006335
3949.0533584346344
Iter: 40 loss: 0.14550273465662153
3948.4845721553893
Iter: 41 loss: 0.14549979103340621
3948.366354939491
Iter: 42 loss: 0.14549958498694193
3948.3351485547164
Iter: 43 loss: 0.14549957627006335
4015.8518984882753
Iter: 44 loss: 0.15000830349473943
3954.046873572649
Iter: 45 loss: 0.14554866236310118
3949.4182020873523
Iter: 46 loss: 0.14550198798805553
3948.5594666256411
Iter: 47 loss: 0.1454999674834131
3948.381461832972
Iter: 48 loss: 0.14549964443019986
3948.3447444165172
Iter: 49 loss: 0.14549958985212424
3948.33713822057
Iter: 50 loss: 0.14549957906303018
3948.3355611670086
Iter: 51 loss: 0.14549957684826276
3948.3352341239652
Iter: 52 loss: 0.14549957638993019
3948.3351663005415
Iter: 53 loss: 0.1454995762949195
3948.335152234984
Iter: 54 loss: 0.14549957627521687
3948.3351493179407
Iter: 55 loss: 0.1454995762711313
3948.3351487130267
Iter: 56 loss: 0.14549957627028481
3948.3351485875246
Iter: 57 loss: 0.14549957627010884
3948.3351485615262
Iter: 58 loss: 0.14549957627007276
3948.3351485561407
Iter: 59 loss: 0.14549957627006443
3948.3351485550038
Iter: 60 loss: 0.14549957627006363
3948.3351485547573
Iter: 61 loss: 0.14549957627006388
3948.3351485547187
Iter: 62 loss: 0.14549957627006332
3948.3351485547714
Iter: 63 loss: 0.14549957627006332
3948.3351485547619
Iter: 64 loss: 0.145499576270064
3948.3351485547746
Iter: 65 loss: 0.1454995762700633
3948.3351485547719
Iter: 66 loss: 0.14549957627006355
3948.3351485547764
Iter: 67 loss: 0.14549957627006335
3948.3351485547746
Iter: 68 loss: 0.14549957627006332
Iter: 1 loss: 0.00044770848624864172
Iter: 2 loss: 0.0003833249504217735
Iter: 3 loss: 0.76480526808796134
Iter: 4 loss: 0.00038318512234321718
Iter: 5 loss: 0.00038304495862201318
Iter: 6 loss: 0.0087840182747948338
Iter: 7 loss: 0.00027458384635341895
Iter: 8 loss: 0.00044631098818522939
Iter: 9 loss: 0.00023100437093276404
Iter: 10 loss: 0.00022767539709373121
Iter: 11 loss: 0.00032589163718902938
Iter: 12 loss: 0.00022692681641041075
