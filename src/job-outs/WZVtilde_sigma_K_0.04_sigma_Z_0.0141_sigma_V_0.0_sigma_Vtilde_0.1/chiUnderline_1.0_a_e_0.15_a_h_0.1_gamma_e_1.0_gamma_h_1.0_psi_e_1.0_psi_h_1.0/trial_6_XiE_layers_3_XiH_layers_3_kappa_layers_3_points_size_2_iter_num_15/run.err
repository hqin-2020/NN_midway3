2022-09-25 18:56:14.026124: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2022-09-25 18:56:14.031903: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/cudnn-8.3.1-el8-x86_64/lib64
2022-09-25 18:56:14.031931: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2022-09-25 18:56:18.674724: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/cudnn-8.3.1-el8-x86_64/lib64
2022-09-25 18:56:18.674756: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-09-25 18:56:18.674773: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (midway3-0124.rcc.local): /proc/driver/nvidia/version does not exist
2022-09-25 18:56:18.675168: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-25 18:56:56.021391: W tensorflow/core/common_runtime/forward_type_inference.cc:231] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:
type_id: TFT_OPTIONAL
args {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_TENSOR
    args {
      type_id: TFT_BOOL
    }
  }
}
 is neither a subtype nor a supertype of the combined inputs preceding it:
type_id: TFT_OPTIONAL
args {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_TENSOR
    args {
      type_id: TFT_DOUBLE
    }
  }
}

	while inferring type of node 'StatefulPartitionedCall_1/StatefulPartitionedCall/cond_1_259/output/_29750'
Iter: 1 loss: 0.055887730397652276
Iter: 2 loss: 0.10423776968554797
Iter: 3 loss: 0.049307993831919625
Iter: 4 loss: 0.045063745039517281
Iter: 5 loss: 0.01801959335086397
Iter: 6 loss: 0.018821832022264198
Iter: 7 loss: 0.006875153548724644
Iter: 8 loss: 0.0035817416977912573
Iter: 9 loss: 0.0013084949233144942
Iter: 10 loss: 0.000983077572781843
Iter: 11 loss: 0.00086774935951417322
Iter: 12 loss: 0.00077712003135045919
Iter: 13 loss: 0.000771561143888513
Iter: 14 loss: 0.0007655530486551747
Iter: 15 loss: 0.0007178207944465039
Iter: 16 loss: 0.00064584281895949385
Iter: 17 loss: 0.00061793032990562348
Iter: 18 loss: 0.00060670512600192322
Iter: 19 loss: 0.00058675745804502122
Iter: 20 loss: 0.000566611802362108
Iter: 21 loss: 0.000543353041300615
Iter: 22 loss: 0.00053885191830866774
Iter: 23 loss: 0.0005353002999012971
Iter: 24 loss: 0.0005345843762523478
Iter: 25 loss: 0.0005332619796086656
Iter: 26 loss: 0.00052890294196198881
Iter: 27 loss: 0.00051946914962700311
Iter: 28 loss: 0.00050767308939676293
Iter: 29 loss: 0.00049782040607879315
Iter: 30 loss: 0.000490232633934536
Iter: 31 loss: 0.0004887589933295839
Iter: 32 loss: 0.00048644787977459415
Iter: 33 loss: 0.00047999699228149282
Iter: 34 loss: 0.00046958529123653165
Iter: 35 loss: 0.00045326593717843371
Iter: 36 loss: 0.00042655397841459748
Iter: 37 loss: 0.00041975222915412782
Iter: 38 loss: 0.00039246000921248025
Iter: 39 loss: 0.00037650064575691679
Iter: 40 loss: 0.00039857447581350829
Iter: 41 loss: 0.00035891733978164612
Iter: 42 loss: 0.00034144372512164386
Iter: 43 loss: 0.00034030803244654214
Iter: 44 loss: 0.00032114326787723089
Iter: 45 loss: 0.00029599977865082017
Iter: 46 loss: 0.00028884467312612945
Iter: 47 loss: 0.00029173793969204854
Iter: 48 loss: 0.00028574891178660537
Iter: 49 loss: 0.00028388020206903362
Iter: 50 loss: 0.00028278123640442811
Iter: 51 loss: 0.00027577256628214778
Iter: 52 loss: 0.00025625674553904712
Iter: 53 loss: 0.00063628966134394581
Iter: 54 loss: 0.00023205496333161086
Iter: 55 loss: 0.00033109543015540815
Iter: 56 loss: 0.00020092381879955088
Iter: 57 loss: 0.00013343826994367358
Iter: 58 loss: 6.7875506065544623e-05
Iter: 59 loss: 6.2096407161464832e-05
Iter: 60 loss: 5.8170757648923696e-05
Iter: 61 loss: 6.0572878602293711e-05
Iter: 62 loss: 5.7313449023920332e-05
Iter: 63 loss: 5.5390142673144515e-05
Iter: 64 loss: 5.2605098028725506e-05
Iter: 65 loss: 5.0197613398372928e-05
Iter: 66 loss: 4.9980300171087794e-05
Iter: 67 loss: 4.9524119167378434e-05
Iter: 68 loss: 4.8902566773984272e-05
Iter: 69 loss: 4.7087563643154521e-05
Iter: 70 loss: 4.4072556217963934e-05
Iter: 71 loss: 4.1032400586394543e-05
Iter: 72 loss: 3.7633706126133772e-05
Iter: 73 loss: 3.6821645678399736e-05
Iter: 74 loss: 3.64393077730387e-05
Iter: 75 loss: 3.5789393908669767e-05
Iter: 76 loss: 3.4806502124723709e-05
Iter: 77 loss: 3.3436805470348917e-05
Iter: 78 loss: 3.2373744611636804e-05
Iter: 79 loss: 3.1819682212831272e-05
Iter: 80 loss: 3.1736859095425938e-05
Iter: 81 loss: 3.1473133525549594e-05
Iter: 82 loss: 3.0963850339075034e-05
Iter: 83 loss: 3.0664708707896334e-05
Iter: 84 loss: 3.0441206763927823e-05
Iter: 85 loss: 3.0314615921239078e-05
Iter: 86 loss: 3.002809493092607e-05
Iter: 87 loss: 3.013936335420904e-05
Iter: 88 loss: 2.9641932070007943e-05
Iter: 89 loss: 2.9392170915786331e-05
Iter: 90 loss: 2.9164817462927015e-05
Iter: 91 loss: 2.9505590631873477e-05
Iter: 92 loss: 2.8084570198452525e-05
Iter: 93 loss: 2.702411335947073e-05
Iter: 94 loss: 2.6233658827398891e-05
Iter: 95 loss: 2.5778172806289588e-05
Iter: 96 loss: 2.5928367507736496e-05
Iter: 97 loss: 2.5375916380991377e-05
Iter: 98 loss: 2.4842992519838533e-05
Iter: 99 loss: 2.4105200653337313e-05
Iter: 100 loss: 2.3531959365756008e-05
Iter: 101 loss: 2.2252562145092218e-05
Iter: 102 loss: 2.1927177844016114e-05
Iter: 103 loss: 2.1846995508687475e-05
Iter: 104 loss: 2.1452316589215059e-05
Iter: 105 loss: 2.1374321146308357e-05
Iter: 106 loss: 2.1339022128736039e-05
Iter: 107 loss: 2.1303171863476842e-05
Iter: 108 loss: 2.1276022141121352e-05
Iter: 109 loss: 2.1251964995677354e-05
Iter: 110 loss: 2.1165440728826377e-05
Iter: 111 loss: 2.0748037947190402e-05
Iter: 112 loss: 2.0236276625427555e-05
Iter: 113 loss: 1.9376317216591874e-05
Iter: 114 loss: 1.8068362806687163e-05
Iter: 115 loss: 1.6760300091411283e-05
Iter: 116 loss: 1.5941491099349238e-05
Iter: 117 loss: 1.5132357037102781e-05
Iter: 118 loss: 1.455108844897126e-05
Iter: 119 loss: 1.3913517609925103e-05
Iter: 120 loss: 1.2995988358249572e-05
Iter: 121 loss: 1.2451158386677548e-05
Iter: 122 loss: 1.2028016483337748e-05
Iter: 123 loss: 1.1801779405652225e-05
Iter: 124 loss: 1.1314395407982592e-05
Iter: 125 loss: 1.1307604420211601e-05
Iter: 126 loss: 1.1096710478516805e-05
Iter: 127 loss: 1.0632334404342707e-05
Iter: 128 loss: 1.0233419955810688e-05
Iter: 129 loss: 9.9300805324366778e-06
Iter: 130 loss: 9.5200115489393768e-06
Iter: 131 loss: 9.2246005347092632e-06
Iter: 132 loss: 9.2192525456840427e-06
Iter: 133 loss: 9.0373934251664058e-06
Iter: 134 loss: 8.6138103174227911e-06
Iter: 135 loss: 8.561334423940568e-06
Iter: 136 loss: 8.5461322411015929e-06
Iter: 137 loss: 8.532397419558436e-06
Iter: 138 loss: 8.523567977490694e-06
Iter: 139 loss: 8.5101881998960375e-06
Iter: 140 loss: 8.4770344433088841e-06
Iter: 141 loss: 8.4338355570733824e-06
Iter: 142 loss: 8.2267574385976882e-06
Iter: 143 loss: 7.883524264447041e-06
Iter: 144 loss: 7.5598183360013388e-06
Iter: 145 loss: 7.3206573746914362e-06
Iter: 146 loss: 7.2958135023741604e-06
Iter: 147 loss: 7.2312447055878944e-06
Iter: 148 loss: 7.206538036966207e-06
Iter: 149 loss: 7.1650367361767752e-06
Iter: 150 loss: 7.0985720123958014e-06
Iter: 151 loss: 6.9720927281427085e-06
Iter: 152 loss: 6.8036014902254993e-06
Iter: 153 loss: 6.7365028718327415e-06
Iter: 154 loss: 6.72971082207458e-06
Iter: 155 loss: 6.71544881819012e-06
Iter: 156 loss: 6.7116295775870856e-06
Iter: 157 loss: 6.7080955215077983e-06
Iter: 158 loss: 6.6978024313976249e-06
Iter: 159 loss: 6.6734129523487632e-06
Iter: 160 loss: 6.6094682292679028e-06
Iter: 161 loss: 6.5089176789826349e-06
Iter: 162 loss: 6.2907831046123189e-06
Iter: 163 loss: 6.75900725962499e-06
Iter: 164 loss: 6.0338761215155771e-06
Iter: 165 loss: 6.0184157959545829e-06
Iter: 166 loss: 5.9787967827857558e-06
Iter: 167 loss: 5.9416338777411013e-06
Iter: 168 loss: 5.9268254393926271e-06
Iter: 169 loss: 5.90217747970849e-06
Iter: 170 loss: 5.8780499327124739e-06
Iter: 171 loss: 5.8404403578949646e-06
Iter: 172 loss: 5.7964310192435542e-06
Iter: 173 loss: 5.7469546323256723e-06
Iter: 174 loss: 5.7172506777726042e-06
Iter: 175 loss: 5.7020453472565816e-06
Iter: 176 loss: 5.6940822112278732e-06
Iter: 177 loss: 5.6908643331482546e-06
Iter: 178 loss: 5.6868906832113024e-06
Iter: 179 loss: 5.6827815465716013e-06
Iter: 180 loss: 5.6767860071931737e-06
Iter: 181 loss: 5.6689601079145809e-06
Iter: 182 loss: 5.6403392031338253e-06
Iter: 183 loss: 5.617922546486165e-06
Iter: 184 loss: 5.5793121507240653e-06
Iter: 185 loss: 5.5458359971118417e-06
Iter: 186 loss: 5.5039267988596842e-06
Iter: 187 loss: 5.4456619617469067e-06
Iter: 188 loss: 5.3431962042236982e-06
Iter: 189 loss: 5.237032840970309e-06
Iter: 190 loss: 5.267421828752226e-06
Iter: 191 loss: 5.1908485081181828e-06
Iter: 192 loss: 5.1736496062054322e-06
Iter: 193 loss: 5.1681556441142524e-06
Iter: 194 loss: 5.1661420139644692e-06
Iter: 195 loss: 5.1630770377378032e-06
Iter: 196 loss: 5.1580914379054384e-06
Iter: 197 loss: 5.1520015636498791e-06
Iter: 198 loss: 5.1441699983873071e-06
Iter: 199 loss: 5.1279917371687381e-06
Iter: 200 loss: 5.0883534415391274e-06
Iter: 201 loss: 5.0438907855209431e-06
Iter: 202 loss: 4.9894342771729181e-06
Iter: 203 loss: 4.9805440546374312e-06
Iter: 204 loss: 4.9300785435211339e-06
Iter: 205 loss: 4.7752796444939152e-06
Iter: 206 loss: 5.2282414951275933e-06
Iter: 207 loss: 4.6927759349131646e-06
Iter: 208 loss: 4.6328985256862167e-06
Iter: 209 loss: 4.5729176242333138e-06
Iter: 210 loss: 4.5564943144241516e-06
Iter: 211 loss: 4.5501496163449587e-06
Iter: 212 loss: 4.545707394270759e-06
Iter: 213 loss: 4.5444391689721573e-06
Iter: 214 loss: 4.5431382412618643e-06
Iter: 215 loss: 4.5421035647826939e-06
Iter: 216 loss: 4.5391301251808011e-06
Iter: 217 loss: 4.5356346909275643e-06
Iter: 218 loss: 4.5281968129716467e-06
Iter: 219 loss: 4.5157277066618378e-06
Iter: 220 loss: 4.498893427781328e-06
Iter: 221 loss: 4.4804615523026516e-06
Iter: 222 loss: 4.4591938339383172e-06
Iter: 223 loss: 4.42831722562431e-06
Iter: 224 loss: 4.3718520762680612e-06
Iter: 225 loss: 4.2902811616127275e-06
Iter: 226 loss: 4.6407525222192825e-06
Iter: 227 loss: 4.24511342576013e-06
Iter: 228 loss: 4.1975718912599477e-06
Iter: 229 loss: 4.1522725090700938e-06
Iter: 230 loss: 4.1206918868692148e-06
Iter: 231 loss: 4.1231541501951611e-06
Iter: 232 loss: 4.103777478797281e-06
Iter: 233 loss: 4.0992228657561293e-06
Iter: 234 loss: 4.08726090903452e-06
Iter: 235 loss: 4.0711799557231191e-06
Iter: 236 loss: 4.0591748619694472e-06
Iter: 237 loss: 4.0478226018205527e-06
Iter: 238 loss: 4.0402023302349657e-06
Iter: 239 loss: 4.0376929048239572e-06
Iter: 240 loss: 4.03621869124617e-06
Iter: 241 loss: 4.0347977259114108e-06
Iter: 242 loss: 4.0338411642450746e-06
Iter: 243 loss: 4.0333122566577215e-06
Iter: 244 loss: 4.03301211833605e-06
Iter: 245 loss: 4.0325750667267883e-06
Iter: 246 loss: 4.0505311722264759e-06
Iter: 247 loss: 4.0319313922423029e-06
Iter: 248 loss: 4.0296321566684789e-06
Iter: 249 loss: 4.0215727698749346e-06
Iter: 250 loss: 4.0087288119370106e-06
Iter: 251 loss: 3.9913018335932631e-06
Iter: 252 loss: 3.975809300489178e-06
Iter: 253 loss: 3.96590574763822e-06
Iter: 254 loss: 3.9477480128443424e-06
Iter: 255 loss: 3.9231011062172667e-06
Iter: 256 loss: 3.9092393775294843e-06
Iter: 257 loss: 3.8956102839271849e-06
Iter: 258 loss: 3.855867060028945e-06
Iter: 259 loss: 3.8690104975139965e-06
Iter: 260 loss: 3.8440230124587005e-06
Iter: 261 loss: 3.8285592240880215e-06
Iter: 262 loss: 3.80898957553345e-06
Iter: 263 loss: 3.7941304771210979e-06
Iter: 264 loss: 3.7784923273678852e-06
Iter: 265 loss: 3.7579407155335694e-06
Iter: 266 loss: 3.7325915060219292e-06
Iter: 267 loss: 3.7046661822495594e-06
Iter: 268 loss: 1.1125192185163284e-05
Iter: 269 loss: 3.6750960360126091e-06
Iter: 270 loss: 3.6519308657333871e-06
Iter: 271 loss: 3.6178279439818049e-06
Iter: 272 loss: 3.6552448579860371e-06
Iter: 273 loss: 3.58653002678746e-06
Iter: 274 loss: 3.6268571165119415e-06
Iter: 275 loss: 3.5710164179108818e-06
Iter: 276 loss: 3.5515013426456727e-06
Iter: 277 loss: 3.5297960804173321e-06
Iter: 278 loss: 3.5274051171749074e-06
Iter: 279 loss: 3.5203052438902897e-06
Iter: 280 loss: 3.5040891301225756e-06
Iter: 281 loss: 3.4803638961896308e-06
Iter: 282 loss: 3.4657454776836918e-06
Iter: 283 loss: 3.4591458564583913e-06
Iter: 284 loss: 3.4472128759514628e-06
Iter: 285 loss: 3.4397851814360924e-06
Iter: 286 loss: 3.431330725943505e-06
Iter: 287 loss: 3.4270265258693204e-06
Iter: 288 loss: 3.4226803627027544e-06
Iter: 289 loss: 3.4167980050141225e-06
Iter: 290 loss: 3.4141578294294115e-06
Iter: 291 loss: 3.4091506538020715e-06
Iter: 292 loss: 3.4051273620944291e-06
Iter: 293 loss: 3.3992119517299648e-06
Iter: 294 loss: 3.38462005830047e-06
Iter: 295 loss: 3.3747562305084469e-06
Iter: 296 loss: 3.3672120640803689e-06
Iter: 297 loss: 3.3872984347468296e-06
Iter: 298 loss: 3.3437204176325775e-06
Iter: 299 loss: 3.3203643590400117e-06
Iter: 300 loss: 3.33000247713764e-06
slurmstepd: error: *** JOB 4560756 ON midway3-0124 CANCELLED AT 2022-09-25T18:58:02 ***
